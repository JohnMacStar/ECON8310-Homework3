# -*- coding: utf-8 -*-
"""Assignment3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gwP-FGEGJJM6vJ8WArXWTE9uRiLTRZAa
"""

# For reading data
import pandas as pd
import gzip
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import numpy as np

# For visualizing
import plotly.express as px

# For model building
import torch
import torch.nn as nn
import torch.nn.functional as F

class CustomMNIST(Dataset):
    def __init__(self, image_data, label_data):
        with gzip.open(label_data, "rb") as f:
          self.raw_label_data = np.frombuffer(f.read(), dtype='uint8', offset = 8)
        self.raw_label_data = pd.DataFrame(self.raw_label_data.reshape(len(self.raw_label_data),1))
        self.raw_label_data.columns = ["labels"]

        with gzip.open(image_data, "rb") as f:
          self.raw_image_data = pd.DataFrame(np.frombuffer(f.read(), dtype = 'uint8', offset = 16).reshape(len(self.raw_label_data), 784))
        self.complete_raw_data = pd.concat([self.raw_label_data, self.raw_image_data], axis = 1)

    def __len__(self):
        return self.complete_raw_data.shape[0]

    def __getitem__(self, idx):
        image = self.complete_raw_data.iloc[idx, 1:].values.reshape(1, 28, 28)
        image = torch.tensor(image, dtype=torch.float32)
        label = self.complete_raw_data.iloc[idx, 0]

        return image, label

train_data = CustomMNIST("train-images-idx3-ubyte.gz", "train-labels-idx1-ubyte.gz")
test_data = CustomMNIST("t10k-images-idx3-ubyte.gz", "t10k-labels-idx1-ubyte.gz")

train_dataloader = DataLoader(train_data, batch_size=64)
test_dataloader = DataLoader(test_data, batch_size=64)

idx=1
clothing_dict = {0:'T-shirt/top', 1:'Trouser', 2:'Pullover', 3:'Dress', 4:'Coat', 5:'Sandal',6:'Shirt',7:'Sneaker',8:'Bag',9:'Ankle boot'}
print(f"This image is labeled a {clothing_dict[train_data.__getitem__(idx)[1]]}")
px.imshow(train_data.__getitem__(idx)[0].reshape(28, 28))

class FirstNet(nn.Module):
    def __init__(self):
      super(FirstNet, self).__init__()
      self.flatten = nn.Flatten()
      self.linear_relu_model = nn.Sequential(
            nn.LazyLinear(10),
        )
    def forward(self, x):
      x = self.flatten(x)
      output = self.linear_relu_model(x)

      return output

model = FirstNet()

learning_rate = 1e-3
batch_size = 64
epochs = 100

loss_fn = nn.CrossEntropyLoss()

optimizer = torch.optim.SGD(model.parameters(),
     lr=learning_rate)

def train_loop(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)
    model.train()
    for batch, (X, y) in enumerate(dataloader):
        pred = model(X)
        loss = loss_fn(pred, y)

        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

        if batch % 10 == 0:
            loss, current = loss.item(), (batch + 1) * len(X)
            print(f"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]")

def test_loop(dataloader, model, loss_fn):
    model.eval()
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    test_loss, correct = 0, 0

    with torch.no_grad():
        for X, y in dataloader:
            pred = model(X)
            test_loss += loss_fn(pred, y).item()
            correct += (pred.argmax(1) == y).type(torch.float).sum().item()

    test_loss /= num_batches
    correct /= size
    print(f"Test Error: \n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \n")

# Need to repeat the training process for each epoch.
#   In each epoch, the model will eventually see EVERY
#   observations in the data

for t in range(epochs):
    print(f"Epoch {t+1}\n-------------------------------")
    train_loop(train_dataloader, model, loss_fn, optimizer)
    test_loop(test_dataloader, model, loss_fn)
print("Done!")

# Decide if we are loading for predictions or more training
model.eval()
# - or -
# model.train()

# Make predictions
pred = model(test_data.__getitem__(1)[0]).argmax()
truth = test_data.__getitem__(1)[1]
print(f"This image is predicted to be a {pred}, and is labeled as {truth}")

# Save our model for later, so we can train more or make predictions

EPOCH = epochs
# We use the .pt file extension by convention for saving
#    pytorch models
PATH = "model.pt"

# The save function creates a binary storing all our data for us
torch.save({
            'epoch': EPOCH,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            }, PATH)

# Specify our path
PATH = "model.pt"

# Create a new "blank" model to load our information into
model = FirstNet()

# Recreate our optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Load back all of our data from the file
checkpoint = torch.load(PATH)
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
EPOCH = checkpoint['epoch']